from flask import Flask, request, render_template, jsonify, session
import pandas as pd
import numpy as np
import faiss, re, os, json
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import random

app = Flask(__name__)
app.secret_key = "change_this_to_a_secure_random_string"

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))



df = pd.read_csv("embeddings/clean_data.csv")
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
index = faiss.read_index("embeddings/faiss_index.idx")


if "row_id" not in df.columns:
    df["row_id"] = df.index

DEFAULT_PREFS = {
    "answers": {},
    "asked": [],
    "pending_key": "price",
    "last_question": None,
    "_skip": [],
    "extra_done": False,
    "stage": None,
    "last_results": []
}

def reset_state_all():
    """‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (prefs + session) ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≠‡∏ô‡∏°‡∏µ request context"""
    try:
        session.clear()
    except Exception:
        pass
    save_prefs(DEFAULT_PREFS.copy())
    return DEFAULT_PREFS.copy()

boot_done = False
@app.before_request
def boot_reset_once():
    global boot_done
    if not boot_done:
        reset_state_all()
        boot_done = True

def json_safe(obj):
    if isinstance(obj, np.generic):
        return obj.item()
    if isinstance(obj, (list, tuple)):
        return [json_safe(x) for x in obj]
    if isinstance(obj, dict):
        return {k: json_safe(v) for k, v in obj.items()}
    return obj

def get_prefs():
    prefs = session.get("prefs")
    if not isinstance(prefs, dict):
        prefs = {"answers": {}, "asked": [], "pending_key": None, "last_question": None}
    return prefs

def save_prefs(prefs):
    session["prefs"] = json_safe(prefs)

def safe_int(v):
    try:
        return int(v) if pd.notna(v) else None
    except:
        return None

def safe_float(v):
    try:
        return float(v) if pd.notna(v) else None
    except:
        return None

def parse_gears(v):
    if v is None:
        return None
    n = pd.to_numeric(v, errors="coerce")
    if pd.notna(n):
        try:
            return int(n)
        except:
            pass
    m = re.search(r"(\d+)", str(v))
    return int(m.group(1)) if m else None

def extract_price_range(query: str):
    if not query:
        return (None, None)
    s = (query or "").lower().strip()
    thai_digits = "‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô"
    s = (
        s.translate(str.maketrans(thai_digits, "0123456789"))
        .replace(",", "")
        .replace(" ", "")
    )

    def to_number(token: str):
        m = re.match(r"(?P<num>\d+(\.\d+)?)(?P<u>‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?", token)
        if not m:
            return None
        num = float(m.group("num"))
        u = m.group("u")
        mul = 1
        if u == "‡∏•‡πâ‡∏≤‡∏ô":
            mul = 1_000_000
        elif u == "‡πÅ‡∏™‡∏ô":
            mul = 100_000
        elif u == "‡∏´‡∏°‡∏∑‡πà‡∏ô":
            mul = 10_000
        elif u in ("‡∏û‡∏±‡∏ô", "k"):
            mul = 1_000
        return int(num * mul)
    m_no_more = re.search(r"‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô\s*(\d+(\.\d+)?(‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?)", s)
    if m_no_more:
        x = to_number(m_no_more.group(1))
        if x:
            return (0, x)

    m_between = re.search(
        r"(‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á|‡∏ä‡πà‡∏ß‡∏á|‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà)?(\d+(\.\d+)?(‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?)\s*(‡∏ñ‡∏∂‡∏á|-)\s*(\d+(\.\d+)?(‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?)",
        s,
    )
    if m_between:
        a = to_number(m_between.group(2))
        b = to_number(m_between.group(6))
        if a and b:
            return (min(a, b), max(a, b))

    m_budget_unbounded = re.search(r"(‡∏á‡∏ö\s*)?(?<!‡πÑ‡∏°‡πà)(‡πÄ‡∏Å‡∏¥‡∏ô|‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤|>)+\s*(\d+(\.\d+)?(‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?)", s)
    if m_budget_unbounded:
        return (None, None)

    m_one = re.search(r"(\d+(\.\d+)?(‡∏•‡πâ‡∏≤‡∏ô|‡πÅ‡∏™‡∏ô|‡∏´‡∏°‡∏∑‡πà‡∏ô|‡∏û‡∏±‡∏ô|k)?)", s)
    if m_one:
        x = to_number(m_one.group(1))
        if x:
            return (max(0, x - 100_000), x + 100_000)

    return (None, None)

def extract_make_from_query(query):
    if not query:
        return None
    q = str(query).strip().lower()
    if not q:
        return None

    found = {}

    
    makes = df["make"].dropna().astype(str).str.lower().unique().tolist()
    for mk in makes:
        if mk in q:
            found["make"] = mk
            break  
    if "series" in df.columns:
        all_series = (
            df["series"].dropna().astype(str).str.lower().unique().tolist()
        )
        for sr in all_series:
            root = sr.split()[0]  
            if sr in q or root in q:
                found["series"] = root  
                break
    return found or None

df["type"] = df.get("type").fillna("").astype(str)
df["type_norm"] = df["type"].str.lower().str.strip()

BODY_MAP = {
    "pickup": "pickup", "truck": "pickup", "‡∏Å‡∏£‡∏∞‡∏ö‡∏∞": "pickup",
    "sedan": "sedan", "saloon": "sedan", "‡πÄ‡∏Å‡πã‡∏á": "sedan", "‡∏£‡∏ñ‡πÄ‡∏Å‡πã‡∏á": "sedan",
    "suv": "suv",
    "mpv": "mpv", "van": "mpv",
    "hatchback": "hatchback"
}

def fuel_to_thai(x):
    s = str(x).strip().lower()
    mapping = {
        "diesel": "‡∏î‡∏µ‡πÄ‡∏ã‡∏•",
        "petrol": "‡πÄ‡∏ö‡∏ô‡∏ã‡∏¥‡∏ô",
        "gasoline": "‡πÄ‡∏ö‡∏ô‡∏ã‡∏¥‡∏ô",
        "ev": "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤",
        "bev": "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤",
        "hybrid": "‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î",
        "hev": "‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î",
        "e:hev": "‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î",
        "phev": "‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î",
        "plug-in hybrid": "‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î",
        "e20": "E20",
        "e85": "E85",
        "cng": "CNG",
        "lpg": "LPG",
        "mhev": "‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î‡πÅ‡∏ö‡∏ö MHEV",
    }
    return mapping.get(s, None)

USAGE_HINTS = [
    "‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß",
    "‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏Å‡∏•",
    "‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á",
    "‡∏≠‡∏≠‡∏ü‡πÇ‡∏£‡∏î",
    "‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å",
    "‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô",
    "‡πÅ‡∏£‡∏á",
    "‡∏Å‡∏ß‡πâ‡∏≤‡∏á",
    "‡∏Ñ‡∏≠‡∏°‡πÅ‡∏û‡∏Ñ",
    "suv",
    "‡∏ã‡∏µ‡∏î‡∏≤‡∏ô",
    "‡∏Å‡∏£‡∏∞‡∏ö‡∏∞",
    "mpv",
    "‡∏Ç‡∏ô‡∏Ç‡∏≠‡∏á",
    "‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏Ç‡∏≤",
]
TRANS_HINTS = {
    "AT": ["‡∏≠‡∏≠‡πÇ‡∏ï‡πâ", "‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥", "auto", "at", "cvt", "dct", "‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"],
    "MT": ["‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", "‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", "manual", "mt"],
}
BODY_HINTS = {
    "suv": ["suv", "‡πÄ‡∏≠‡∏™‡∏¢‡∏π‡∏ß‡∏µ"],
    "sedan": ["‡∏ã‡∏µ‡∏î‡∏≤‡∏ô", "sedan","‡πÄ‡∏Å‡πã‡∏á","‡∏£‡∏ñ‡πÄ‡∏Å‡πã‡∏á"],
    "hatchback": ["‡πÅ‡∏Æ‡∏ó‡∏ä‡πå", "hatch"],
    "mpv": ["mpv", "‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß", "7‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á", "7 ‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á", "‡∏≠‡πÄ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå"],
    "pickup": ["‡∏Å‡∏£‡∏∞‡∏ö‡∏∞", "‡∏õ‡∏¥‡∏Ñ‡∏≠‡∏±‡∏û", "‡∏õ‡∏¥‡∏Å‡∏≠‡∏±‡∏û", "pickup","‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞"],
}
FUEL_HINTS = {
    "diesel": ["‡∏î‡∏µ‡πÄ‡∏ã‡∏•", "diesel"],
    "petrol": ["‡πÄ‡∏ö‡∏ô‡∏ã‡∏¥‡∏ô", "gasoline", "petrol"],
    "hybrid": ["‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î", "hev", "mhev", "phev", "‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô"],
    "ev": ["‡πÑ‡∏ü‡∏ü‡πâ‡∏≤", "ev", "bev"],
}
NO_WORDS = ("‡πÑ‡∏°‡πà‡∏°‡∏µ", "‡πÑ‡∏°‡πà‡πÄ‡∏ô‡πâ‡∏ô", "‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ", "‡πÄ‡∏â‡∏¢‡πÜ", "‡πÄ‡∏â‡∏¢ ‡πÜ", "‡∏¢‡∏±‡∏á", "‡πÑ‡∏°‡πà", "‡∏Ç‡πâ‡∏≤‡∏°")

def _extract_usage(text):
    return [k for k in USAGE_HINTS if k in (text or "").lower()]


def _extract_transmission(text):
    s = (text or "").lower()
    for k, kws in TRANS_HINTS.items():
        if any(w in s for w in kws):
            return k
    return None

def _extract_fuel(text):
    s = (text or "").lower()
    for name, kws in FUEL_HINTS.items():
        if any(w in s for w in kws):
            return name
    return None


ASK_ORDER = [
    "make",       
    "usage",       
    "trans",       
    "price",       
    "fuel",
    "drive",        
    "extra",       
]

ASK_VARIANTS = {
    "make": [
        "‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡∏£‡∏ñ‡∏£‡∏∏‡πà‡∏ô‡πÑ‡∏´‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
        "‡∏û‡∏≠‡∏à‡∏∞‡∏°‡∏µ‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
    ],
    "usage_text": [
        "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏£‡∏ñ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏Å‡∏• ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏Ç‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡∏ö?",
        "‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÜ ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ö‡πà‡∏≠‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ?",
        "‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏õ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß?",
    ],
    "trans": [
        "‡∏ä‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö?",
        "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
    ],
    "price": [
        "‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏ñ‡∏Ñ‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏£‡∏±‡∏ö?",
        "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏£‡∏ñ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏µ‡πà‡∏ö‡∏≤‡∏ó‡∏Ñ‡∏£‡∏±‡∏ö?",
        "‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏á‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
    ],
    "fuel": [
        "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏´‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ö‡∏ô‡∏ã‡∏¥‡∏ô ‡∏î‡∏µ‡πÄ‡∏ã‡∏• ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¥‡πà‡∏ô‡πÜ",
    ],
    "drive": [
        "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ , ‡∏Ç‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏á  ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏±‡∏ö‡∏™‡∏µ‡πà ‡∏Ñ‡∏£‡∏±‡∏ö?",
    ],
    "extra": [
        "‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô cc ‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤ ‡∏™‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÜ?",
    ],
}
SYSTEM_QUESTIONER = """
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
‡∏û‡∏π‡∏î‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô '‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö', '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö'
‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ '?' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
"""

def llm_generate_question(
    field: str, answers: dict, last_question: str = ""
) -> str | None:
    """
    ‡πÉ‡∏´‡πâ LLM ‡πÅ‡∏ï‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏î ‡πÜ ‡∏ï‡∏≤‡∏° field ‡πÅ‡∏•‡∏∞ context ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ
    ‡∏Ñ‡∏∑‡∏ô None ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ fallback
    """
    try:
        ctx = {
            "ask_for": field,
            "known_answers": answers,
            "last_question": last_question or "",
        }
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.9,  
            max_tokens=60,
            messages=[
                {"role": "system", "content": SYSTEM_QUESTIONER},
                {"role": "user", "content": f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {ctx}\n‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"},
            ],
        )
        q = (resp.choices[0].message.content or "").strip()
        
        if not q or q == last_question or len(q.split()) < 3:
            return None
        return q
    except Exception:
        return None
def format_question_for_ui(raw_q: str, answers: dict) -> str:
    user_make = answers.get("make")
    series    = answers.get("series")

    ctx = ""
    if user_make:
        ctx += f"‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö {user_make}"
        if series:
            ctx += f" ‡∏£‡∏∏‡πà‡∏ô {series}"

    system_prompt = (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á "
        "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢ ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏π‡∏î‡∏¢‡∏≤‡∏ß "
        "‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° 1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢"
    )

    user_prompt = f"‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏¥‡∏°: {raw_q}\n‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {ctx}\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏Ç‡∏∂‡πâ‡∏ô"

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.5,
            max_tokens=50,
        )
        new_q = resp.choices[0].message.content.strip()
        return new_q if new_q else raw_q
    except:
        return raw_q


def choose_natural_question(field: str, answers: dict, prefs: dict) -> str:
    last_q = (prefs or {}).get("last_question", "")
    variants = ASK_VARIANTS.get(field, []) or ["‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö?"]
    random.shuffle(variants)
    base_q = variants[0].strip()
    try:
        ctx_parts = []
        for k in ("make","series","usage_text","body","fuel","trans","price","drive"):
            v = answers.get(k)
            if v:
                ctx_parts.append(f"{k}={v}")
        ctx = ", ".join(ctx_parts) or "-"

        prompt = (
            "‡∏£‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ "
            "‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô‡∏ô‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô '‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡πÄ‡∏•‡∏¢', '‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô', '‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤' "
            "‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏™‡∏£‡∏∏‡∏õ/‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á '‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô' ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ '?' \n"
            f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {ctx}\n"
            f'‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô: "{base_q}"'
        )

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=60,
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡∏≤‡∏¢‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß' ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á"},
                {"role": "user", "content": prompt},
            ],
        )
        q = (resp.choices[0].message.content or "").strip()
        q = re.sub(r'^[\'"‚Äú‚Äù]+|[\'"‚Äú‚Äù]+$', '', q) 
        q = re.sub(r'^(‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô(‡πÄ‡∏•‡∏¢)?!?|‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢(‡∏Ñ‡∏£‡∏±‡∏ö)?!?|‡πÇ‡∏≠‡πÄ‡∏Ñ(‡∏Ñ‡∏£‡∏±‡∏ö)?!?)[\s,:-]*', '', q, flags=re.IGNORECASE)
        q = re.sub(r'^(‡∏•‡∏≠‡∏á(‡∏õ‡∏£‡∏±‡∏ö|‡∏ñ‡∏≤‡∏°)‡∏ß‡πà‡∏≤|‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤|‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô|‡πÄ‡∏ä‡πà‡∏ô)[:\s-]*', '', q, flags=re.IGNORECASE)
        if "?" in q:
            q = q.split("?")[0].strip() + "?"
        if not q.endswith("?"):
            q = q.rstrip(" .!~") + "?"
        if not q or len(q.split()) < 3 or q.lower() == base_q.lower():
            q = base_q
        if q == last_q:
            q = base_q if base_q != last_q else (variants[1] if len(variants) > 1 else base_q)
        return q

    except Exception:
        return base_q


def _next_missing_field(answers: dict) -> str | None:
    prefs = get_prefs()
    order = prefs.get("_ask_order")

    if not order:
        middle = ["usage_text", "trans", "fuel", "drive"]  
        random.shuffle(middle)
        order = ["price", "make"] + middle + ["extra"]
        prefs["_ask_order"] = order
        save_prefs(prefs)

    skip = set(prefs.get("_skip", []))
    for f in order:
        if answers.get(f) or f in skip:
            continue
        return f
    return None


def _fallback_question(field: str) -> str:
    prefs = get_prefs()
    return choose_natural_question(field, prefs.get("answers", {}), prefs)

SYSTEM_PLANNER = (
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ '‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÜ' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n"
    "- ‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏ñ (‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì/‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô/‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå/‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á/‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå/‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏á/‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á/‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô/‡∏Ç‡∏ô‡∏≤‡∏î)\n"
    "- ‡∏´‡πâ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞ 1 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
    '‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON: {"ask_for":"<‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö>", "question":"<‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô>"}'
)

def next_question(user_input: str, answers: dict):
    
    miss = _next_missing_field(answers)
    if not miss:
        return {"ask_for": None, "question": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ú‡∏°‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!"}

    variants = ASK_VARIANTS.get(miss, [])
    base_q = random.choice(variants) if variants else "‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö?"

    try:
        ai_prompt = f"‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏î‡∏¥‡∏°: '{base_q}'"
        ai_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏ñ"},
                {"role": "user", "content": ai_prompt},
            ],
            temperature=0.5,
            max_tokens=60,
        )
        q = ai_resp.choices[0].message.content.strip()
        for p in ("‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö!", "‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤", "‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ü‡∏±‡∏á‡∏î‡∏π‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"):
            if q.startswith(p):
                q = q[len(p):].lstrip(" Ôºö:‚Äì-\"'‚Äú‚Äù ").strip()
        q = q.strip('‚Äú‚Äù"\' ')
        if "?" in q:
            q = q.split("?")[0].strip() + "?"
        if not q.endswith("?") or len(q.split()) < 3 or len(q) > 120:
            q = base_q
        if not q or q == base_q or len(q.split()) < 3:
            q = base_q

    except Exception as e:
        q = base_q

    return {"ask_for": miss, "question": q}

def price_llm(text: str) -> tuple[int|None, int|None]:
    
    if not text or not text.strip():
        return (None, None)

    sys = (
        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "price_min/price_max ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏ö‡∏≤‡∏ó ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô '‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô X' ‡πÉ‡∏´‡πâ min=0,max=X; "
        "‡∏ñ‡πâ‡∏≤ '‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà X ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ' ‡πÉ‡∏´‡πâ min=X,max=null; ‡∏ä‡πà‡∏ß‡∏á X‚ÄìY ‡πÉ‡∏´‡πâ min=X,max=Y; "
        "‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö 1,000,000 / 1‡∏•‡πâ‡∏≤‡∏ô / 900k / 0.8m / 7-9‡πÅ‡∏™‡∏ô / ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1 ‡∏•‡πâ‡∏≤‡∏ô "
        "‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏™‡πà‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏•‡∏á‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç"
    )
    user = f"""‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
‡∏ï‡∏≠‡∏ö JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô {{"price_min": 0, "price_max": 1000000}} ‡∏´‡∏£‡∏∑‡∏≠ {{"price_min": 700000, "price_max": 900000}} 
‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö {{"price_min": null, "price_max": null}}"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.0,
            max_tokens=60,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": user},
            ],
        )
        data = json.loads(resp.choices[0].message.content or "{}")
        mn = data.get("price_min")
        mx = data.get("price_max")
        mn = int(mn) if isinstance(mn, (int, float, str)) and str(mn).strip().isdigit() else None
        mx = int(mx) if isinstance(mx, (int, float, str)) and str(mx).strip().isdigit() else None
        return (mn, mx)
    except Exception:
        return (None, None)

def extract_json(text: str) -> dict:
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á JSON object ‡∏Å‡πâ‡∏≠‡∏ô‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å‡∏™‡∏ï‡∏£‡∏¥‡∏á (‡∏Å‡∏±‡∏ô LLM ‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏û‡∏π‡∏î/‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô)
    ‡∏Ñ‡∏∑‡∏ô {} ‡∏ñ‡πâ‡∏≤‡∏î‡∏∂‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"""
    if not text:
        return {}
    text = text.strip()
    try:
        return json.loads(text)
    except Exception:
        pass
    import re
    m = re.search(r"\{.*\}", text, flags=re.DOTALL)
    if not m:
        return {}
    try:
        return json.loads(m.group(0))
    except Exception:
        return {}

def extract_answers(user_input: str, known_answers: dict) -> dict:
    try:
        print("[extract_answers] input:", user_input)
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡∏≤‡∏¢‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå
‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô)
‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: price, usage_text, make, fuel, trans, drive, series
‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô "" (string ‡∏ß‡πà‡∏≤‡∏á) ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏ö‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏¥‡πâ‡∏á

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: "‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡∏•‡πâ‡∏≤‡∏ô ‡∏Ç‡∏≠‡∏î‡∏π nissan"
‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
{{"price": "‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡∏•‡πâ‡∏≤‡∏ô", "make": "nissan", "series": "", "usage_text": "", "fuel": "", "trans": "", "drive": ""}}

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: "{user_input}"
‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
"""

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.2,         
            max_tokens=120,
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"},
                {"role": "user", "content": prompt},
            ],
        )

        llm_text = (resp.choices[0].message.content or "").strip()
        parsed = extract_json(llm_text)  
        
        mk = extract_make_from_query(user_input)
        if mk:
            known_answers.update(mk)
        if not known_answers.get("usage_text") and parsed.get("usage"):
            known_answers["usage_text"] = parsed["usage"]
            parsed.pop("usage", None)      
            
        print("[extract_answers] raw_llm:", llm_text)
        print("[extract_answers] parsed:", parsed)
        
        allow_keys = {"price","usage_text","make","series","fuel","trans","body","drive"}
        for k, v in parsed.items():
            if k in allow_keys and v:
                known_answers[k] = v

        u_text = known_answers.get("usage_text")
        if isinstance(u_text, str) and u_text.strip():
            t = u_text.lower()

            not_usage_keywords = [
                "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤", "‡πÅ‡∏£‡∏á‡∏™‡∏∏‡∏î", "‡πÄ‡∏£‡πá‡∏ß", "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß", "0-100", "‡πÅ‡∏£‡∏á",    
                "‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå", "‡∏≠‡∏≠‡πÇ‡∏ï‡πâ", "‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥", "‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", "manual", "mt", "at", "cvt", "dct"  
            ]
            if any(k in t for k in not_usage_keywords):
                known_answers.pop("usage", None)   
            else:
                hints = _extract_usage(u_text)
                if hints:
                    known_answers["usage"] = hints
                else:
                    known_answers.pop("usage", None)

        btext = f"{known_answers.get('usage_text','')} {user_input}".lower()

        _body_order = ["sedan", "suv", "mpv", "hatchback", "pickup"]
        detected_body = None

        for _b in _body_order:
            if any(w in btext for w in BODY_HINTS[_b]):
                detected_body = _b
                break

        if detected_body:
            known_answers["body"] = detected_body

        
        
        ttext = f"{(known_answers.get('usage_text') or '')} {user_input}".lower()
        tr = _extract_transmission(ttext)  
        if tr:
            known_answers["trans"] = tr

        if (known_answers.get("usage_text","").strip() in
            ("‡∏≠‡∏≠‡πÇ‡∏ï‡πâ","‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏≠‡πÇ‡∏ï‡πâ","‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥","‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤","‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤","‡∏ä‡∏≠‡∏ö‡∏Ç‡∏±‡∏ö‡∏≠‡∏≠‡πÇ‡∏ï‡πâ")):
            known_answers["usage_text"] = ""
            
        mn, mx = price_llm(user_input)
        if known_answers.get("price") != (None, None):
            if mn is not None or mx is not None:
                known_answers["price"] = (mn or 0, mx or 10_000_000_000)
    except Exception as e:
        print("extract_answers error:", e)
    return known_answers

def detect_reference(user_input: str, last_results: list[dict]) -> int | None:
    if not last_results:
        return None
    m = re.search(r"‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*(\d+)", user_input)
    if m:
        idx = int(m.group(1)) - 1
        return idx if 0 <= idx < len(last_results) else None
    t = user_input.lower()
    for i, r in enumerate(last_results):
        n = (r.get("full_name") or "").lower()
        if n and n in t:
            return i
    return None

def is_efficiency_question(user_input: str) -> bool:
    t = user_input.lower()
    return any(k in t for k in ["‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î", "‡∏Å‡∏¥‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô", "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏õ‡∏•‡∏∑‡∏≠‡∏á", "‡∏Å‡∏°/‡∏•‡∏¥‡∏ï‡∏£", "km/l"])

def is_compare_intent(user_input: str) -> bool:
    t = user_input.lower()
    return ("‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö" in t) or ("‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô" in t) or ("vs" in t) or ("‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö" in t)

def rag_retrieve_context(user_query: str, answers: dict, top_n: int = 5):
   
    query = user_query or ""
    if isinstance(answers, dict):
        if answers.get("make"):
            query += f" {answers['make']}"
        if answers.get("series"):
            query += f" {answers['series']}"
        if answers.get("usage_text"):
            query += f" {answers['usage_text']}"

        try:
            price_min, price_max = (0, 10_000_000_000)
            if answers.get("price"):
                price_min, price_max = answers["price"]

            results = search_similar_rows(
                user_query=query,
                price_min=price_min,
                price_max=price_max,
                target_make=answers.get("make"),
                top_n=top_n,
                usage_hints=answers.get("usage", []),
                answers=answers,
            )
            return results or []            
        except Exception as e:
            print("RAG error:", e)
            return []
    else:
        return []


def rag_answer_followup(user_input, answers_or_rows) -> str:
    
   
    rows = []
    if isinstance(answers_or_rows, list):
        
        rows = answers_or_rows
    elif isinstance(answers_or_rows, dict):
        retrieved = rag_retrieve_context(user_input, answers_or_rows, top_n=5)
        
        if retrieved and isinstance(retrieved[0], (tuple, list)):
            rows = [r[1] for r in retrieved]
        else:
            rows = retrieved or []
    else:
        rows = []

    if not rows:
        return "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á ‡∏•‡∏≠‡∏á‡∏ö‡∏≠‡∏Å‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏µ‡∏Å‡∏ô‡∏¥‡∏î‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö"

    
    try:
        exps = rag_generate_answer(rows, user_query=user_input) or []
    except Exception as e:
        print(" RAG generate error:", e)
        exps = [""] * len(rows)

   
    lines = []
    for i, row in enumerate(rows[:5]):
        title = str(row.get("full_name") or "-")
        expl  = (exps[i] if i < len(exps) else "") or ""
        if expl:
            lines.append(f"{i+1}. {title} ‚Äî {expl}")
        else:
            price_txt = row.get("price_thb")
            price_txt = f"{int(price_txt):,} ‡∏ö‡∏≤‡∏ó" if isinstance(price_txt, (int, float)) else "-"
            lines.append(f"{i+1}. {title} (‡∏£‡∏≤‡∏Ñ‡∏≤ {price_txt})")
    return "\n\n".join(lines)

def search_similar_rows(user_query, price_min=None, price_max=None,
                        target_make=None, top_n=5, usage_hints=None,answers=None,target_series=None):
          
    target_body = (answers or {}).get("body")
    def _row_is_body(row, want):
        t = (row.get("type_norm") or row.get("type") or "").strip().lower()
        t = BODY_MAP.get(t, t)          # map ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
        return (t == want) if want else True

    answers = answers or {}
    qemb = model.encode([user_query]).astype("float32")
    faiss.normalize_L2(qemb)
    
    k = min(max(top_n * 50, 200), index.ntotal)
    scores, indices = index.search(qemb, k)  
    

    matched = []
    for s, idx in zip(scores[0], indices[0]):
        if idx >= len(df):
            continue  
        row = df.iloc[idx]
        if not target_body and usage_hints and ("‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á" in usage_hints):
            if _row_is_body(row, "pickup"):
                continue
        if target_body and not _row_is_body(row, target_body):
            continue 
        try:
            price = float(row["price_thb"])
            make_in_row = str(row.get("make", "")).strip().lower()
            series_in_row = str(row.get("series", "")).strip().lower()
        except Exception:
            continue
        trans_pref = (answers or {}).get("trans")
        if trans_pref:
            name_join = f"{row.get('full_name','')} {row.get('series','')} {row.get('description','')} {row.get('gears','')}"
            name_lc = name_join.lower()
            if trans_pref == "MT":
                if any(k in name_lc for k in ["a/t", " auto", "‡∏≠‡∏≠‡πÇ‡∏ï‡πâ", "cvt", "dct"]):
                    continue
                if re.search(r'\b\d+\s*at\b', name_lc) or re.search(r'\bat\b', name_lc):
                    continue
            if trans_pref == "AT":
                if any(k in name_lc for k in ["m/t", " manual", "‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤"]):
                    continue
                if re.search(r'\b\d+\s*mt\b', name_lc) or re.search(r'\bmt\b', name_lc):
                    continue
        if target_make:
            if isinstance(target_make, str):
                raw = re.split(r'[,\s/&|]+', target_make.lower())
                stop = {"‡πÅ‡∏•‡∏∞", "‡∏Å‡∏±‡∏ö", "‡∏´‡∏£‡∏∑‡∏≠", "and", "or"}
                makes = [m for m in raw if m and m not in stop]
            elif isinstance(target_make, list):
                makes = [m.lower() for m in target_make]
            else:
                makes = []
            car_name = (str(row.get("full_name", "")) + " " + make_in_row).lower()
            if not any(m in car_name for m in makes):
                continue
        if target_series:
            if str(target_series).strip().lower() not in series_in_row:
                continue
        if price_min is not None and price < float(price_min):
            continue
        if price_max is not None and price > float(price_max):
            continue
        matched.append((float(s), row))
        if len(matched) >= top_n:
            break

    if len(matched) < top_n:
        cand = df.copy()
        if target_make:
            cand = cand[
                cand["make"].astype(str).str.lower().str.contains(target_make, na=False)]
        if price_min is not None:
            cand = cand[pd.to_numeric(cand["price_thb"], errors="coerce") >= float(price_min)]
        if price_max is not None:
            cand = cand[pd.to_numeric(cand["price_thb"], errors="coerce") <= float(price_max)]
        if target_body:
            cand = cand[
                cand["type_norm"].apply(lambda t: BODY_MAP.get(str(t).lower(), str(t).lower()) == target_body)]
        if cand.empty and (price_min is not None or price_max is not None):
            cand = df.copy()
            if target_make:
                cand = cand[
                    cand["make"].astype(str).str.lower().str.contains(target_make, na=False)
                ]
            target = price_max if price_max is not None else price_min
            cand["price_diff"] = (
                pd.to_numeric(cand["price_thb"], errors="coerce") - float(target)
            ).abs()
            cand = cand.sort_values("price_diff", ascending=True)

        cand = cand.sort_values("price_thb", ascending=True).head(top_n)

        real_scored = []
        for ridx, r in cand.iterrows():
            try:
                x = np.asarray(index.reconstruct(int(ridx)), dtype="float32")  
                dist = float(((qemb[0] - x) ** 2).sum())                       
            except Exception:
                dist = 1e9 
            real_scored.append((dist, r))
        matched = real_scored

    hints = usage_hints or []

    def _bonus(row):
        bonus = 0.0
        eng = pd.to_numeric(row.get("engine_l"), errors="coerce")
        gears = pd.to_numeric(row.get("gears"), errors="coerce")
        hp = pd.to_numeric(row.get("horsepower_hp"), errors="coerce")
        fuel = (row.get("fuel_type") or "").lower()
        name = (row.get("full_name") or "").lower()

        if "‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏Å‡∏•" in hints:
            if pd.notna(eng) and eng >= 1.5: bonus += 0.35
            if pd.notna(gears) and gears >= 6: bonus += 0.2
            if "diesel" in fuel: bonus += 0.35
            if any(k in name for k in ["suv", "pickup", "navara", "terra"]): bonus += 0.2
            if pd.notna(hp) and hp >= 120: bonus += 0.1

        if "‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á" in hints:
            if pd.notna(eng) and eng <= 1.3: bonus += 0.3
            if "hybrid" in fuel or "hev" in fuel: bonus += 0.2
            if any(k in name for k in ["almera", "march", "yaris", "mazda2"]): bonus += 0.15

        return bonus
    
    def _soft_pref_adjust(row, answers):  
        adj = 0.0
        
        min_hp = answers.get("min_hp")
        if min_hp:
            hp = pd.to_numeric(row.get("horsepower_hp"), errors="coerce")
            if pd.notna(hp) and hp < int(min_hp):
                adj += 0.4

        min_cc = answers.get("min_cc")
        if min_cc:
            cc = pd.to_numeric(row.get("engine_cc"), errors="coerce")
            if pd.notna(cc) and cc < int(min_cc):
                adj += 0.3

        return adj

    ranked = []
    for s, r in matched:
        base = float(s)
        penalty = _soft_pref_adjust(r, answers)
        score = base + penalty - _bonus(r)
        rr = r.copy()                 
        rr["_final_sc"] = float(score)
        ranked.append((score, rr))

    ranked.sort(key=lambda x: x[0])     
    return ranked[:top_n]

def rag_generate_answer(rows, user_query=""):
    explanations = []
    for i, row in enumerate(rows, 1):
        eng_l  = row.get('engine_l')
        eng_cc = row.get('engine_cc')
        engine_line = f"{float(eng_l):.1f} L" if pd.notna(eng_l) else "---"
        if pd.notna(eng_cc):
            try:
                engine_line = (engine_line if engine_line != "---" else "") + f" ({int(eng_cc)} cc)"
                engine_line = engine_line.strip()
            except Exception:
                pass

        ctx = (
            f"‡∏£‡∏∏‡πà‡∏ô: {row.get('full_name','-')}\n"
            f"‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå/‡∏£‡∏∏‡πà‡∏ô‡∏¢‡πà‡∏≠‡∏¢: {row.get('series','-')}\n"
            f"‡∏õ‡∏µ: {row.get('year','-')}\n"
            f"‡∏£‡∏≤‡∏Ñ‡∏≤: {int(row['price_thb']):,} ‡∏ö‡∏≤‡∏ó\n"
            f"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå: {engine_line}\n"
            f"‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤: {row.get('horsepower_hp','---')}\n"
            f"‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á: {row.get('fuel_type','---')}\n"
            f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row.get('description','')}\n"
        )

        prompt = (
            f'‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ:\n{ctx}\n‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: "{user_query}"\n'
            "‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏Ñ‡∏ô‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô ‡πÄ‡∏õ‡πá‡∏ô 2‚Äì3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô "
            "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏£‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πà‡∏ô/‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏∞‡πÑ‡∏£ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ "
            "‡∏¢‡∏∂‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
        )
        try:
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏Ç‡∏≤‡∏¢‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏Å‡πà‡∏á ‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
                max_tokens=700,
            )
            explanations.append((resp.choices[0].message.content or "").strip())
        except Exception as e:
            print(f"RAG GPT error on row {i}: {e}")
            explanations.append("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏î‡πâ")
    return explanations

def llm_followup_answer(user_input, last_results):
    def _eng_text(r):
        eng_l  = r.get('engine_l')
        eng_cc = r.get('engine_cc')
        t = f"{eng_l}L" if eng_l not in (None, "", "nan") else "-"
        if eng_cc not in (None, "", "nan"):
            try:
                t = (t if t != "-" else "") + f" ({int(eng_cc)} cc)"
                t = t.strip()
            except Exception:
                pass
        return t

    lines = []
    for i, r in enumerate(last_results, 1):
        line = (
            f"{i}. {r.get('full_name')} | ‡∏õ‡∏µ {r.get('year','-')} | ‡∏£‡∏≤‡∏Ñ‡∏≤ {r.get('price_thb')} | "
            f"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {_eng_text(r)} | ‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤ {r.get('horsepower_hp','-')} | ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á {r.get('fuel_type','-')} | "
            f"‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå {r.get('gears','-')} | ‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô {r.get('drive','-')}"
        )
        lines.append(line)

    context = "‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ñ 5 ‡∏£‡∏∏‡πà‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏¢‡πà‡∏≠):\n" + "\n".join(lines)

    prompt = (
        f"{context}\n\n"
        f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: \"{user_input}\"\n\n"
        "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å):\n"
        "1) ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏∏‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≤‡∏ß ‡πÜ\n"
        "2) ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‚Äú‡∏Ñ‡∏±‡∏ô‡πÑ‡∏´‡∏ô‚Ä¶‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î/‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‚Äù ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤ **1 ‡∏Ñ‡∏±‡∏ô** ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô ‡πÜ 2‚Äì4 ‡∏Ç‡πâ‡∏≠\n"
        "3) ‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ ‚Äú‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö/‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö/‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î/‡∏ó‡∏±‡πâ‡∏á 5 ‡∏Ñ‡∏±‡∏ô‚Äù ‡∏Ñ‡πà‡∏≠‡∏¢‡∏™‡∏£‡∏∏‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÑ‡∏î‡πâ\n"
        "4) ‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô 5 ‡∏Ñ‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏£‡∏∏‡πà‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ\n"
        "5) ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÅ‡∏ô‡∏∞‡πÅ‡∏ô‡∏ß‡∏ß‡πà‡∏≤ ‚Äú‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÉ‡∏Ñ‡∏£/‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÑ‡∏´‡∏ô‚Äù\n"
    )

    if not client:
        return "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö: ‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡∏ú‡∏°‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡πà‡∏ô‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏°‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ "
                        "‡πÑ‡∏°‡πà‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î "
                        "‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå"
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.6,
            max_tokens=1000,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        print("LLM followup error:", e)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"

def llm_detail_answer(user_input: str, row: dict) -> str:
    eng_l  = row.get('engine_l')
    eng_cc = row.get('engine_cc')
    engine_line = f"{float(eng_l):.1f} L" if eng_l not in (None, "", "nan") else "-"
    if eng_cc not in (None, "", "nan"):
        try:
            engine_line = (engine_line if engine_line != "-" else "") + f" ({int(eng_cc)} cc)"
            engine_line = engine_line.strip()
        except Exception:
            pass

    ctx = (
        f"‡∏£‡∏∏‡πà‡∏ô: {row.get('full_name')}\n"
        f"‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå/‡∏£‡∏∏‡πà‡∏ô‡∏¢‡πà‡∏≠‡∏¢: {row.get('series','-')}\n"
        f"‡∏õ‡∏µ: {row.get('year','-')}\n"
        f"‡∏£‡∏≤‡∏Ñ‡∏≤: {row.get('price_thb')} ‡∏ö‡∏≤‡∏ó\n"
        f"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå: {engine_line}\n"
        f"‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤: {row.get('horsepower_hp')}\n"
        f"‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á: {row.get('fuel_type')}\n"
        f"‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå: {row.get('gears')}\n"
        f"‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô: {row.get('drive')}\n"
        f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row.get('description','')}\n"
    )
    prompt = (
        "‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡πâ‡∏ô: ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏´‡∏•‡∏±‡∏Å, ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î, ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞ (‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á/‡∏ó‡∏≤‡∏á‡πÑ‡∏Å‡∏•/‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß). "
        "‡∏≠‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ **‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÉ‡∏Ñ‡∏£**.\n\n"
        f"{ctx}\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {user_input}"
    )
    if not client:
        return "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô ‡πÜ: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î ‡∏î‡∏π‡πÅ‡∏•‡∏á‡πà‡∏≤‡∏¢"
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.5,
            max_tokens=500,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print("LLM detail error:", e)
        return "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô ‡πÜ: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î ‡∏î‡∏π‡πÅ‡∏•‡∏á‡πà‡∏≤‡∏¢"

@app.route("/")
def home():
    return render_template("index.html")

START_TRIGGERS = [
    "‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
    "start",
    "restart",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà",
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ",
]

def is_new_start(text: str, answers: dict) -> bool:
    triggers = [
        "‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏´‡∏°‡πà",
        "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà", "‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà",
        "‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà", "‡∏´‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢",
        "‡∏≠‡∏¢‡∏≤‡∏Å‡∏´‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏°‡πà", "‡∏Ç‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", "‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà"
    ]
    text = text.lower().strip()
    return any(t in text for t in triggers)

def no_answer(text: str) -> bool:
    t = (text or "").strip().lower()
    return any(w in t for w in NO_WORDS)

WELCOME = "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏Ñ‡∏£‡∏±‡∏ö  ‡∏ú‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì!"
FIRST_Q = "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‚Äî ‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏î‡∏µ?"

@app.route("/chat", methods=["POST"])
def chat():

    has_greeted = bool(session.get("has_greeted"))
    data = request.get_json(force=True) or {}
    user_input = (data.get("message") or "").strip()
    ui = user_input.lower()
    handled_pending = False

    RESET_ALL = ["‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà", "‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï", "reset", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà"]
    NEW_RECO  = ["‡∏Ç‡∏≠‡πÉ‡∏´‡∏°‡πà", "‡∏´‡∏≤‡πÉ‡∏´‡∏°‡πà", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ", "‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà", "‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", "‡∏≠‡∏µ‡∏Å 5 ‡∏Ñ‡∏±‡∏ô", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ä‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà","‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà"]

    if data.get("reset") is True or any(t in ui for t in (RESET_ALL + NEW_RECO)):
        reset_state_all()
        session["has_greeted"] = True
        try:
            first_q = (choose_natural_question(
                "price", get_prefs().get("answers", {}), get_prefs()
            ) or FIRST_Q).strip()
        except Exception:
            first_q = FIRST_Q
        first_q = format_question_for_ui(first_q, get_prefs().get("answers", {}))
        prefs = get_prefs() or {}
        prefs["pending_key"] = "price"
        prefs["last_question"] = first_q
        save_prefs(prefs)
        return jsonify({"mode": "intro", "reply": WELCOME, "next": first_q})


    prefs = get_prefs()
    answers = prefs["answers"]
    prefs.setdefault("_skip", [])


    if any(t in ui for t in (RESET_ALL + NEW_RECO)):
        reset_state_all()
        session["has_greeted"] = True
        if has_greeted:
            return jsonify({"mode": "ask", "reply": "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏°‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‚Äî ‡∏ï‡∏±‡πâ‡∏á‡∏á‡∏ö‡πÑ‡∏ß‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?"})
        else:
            try:
                first_q = (choose_natural_question("price", get_prefs().get("answers", {}), get_prefs()) or FIRST_Q).strip()
            except Exception:
                first_q = FIRST_Q
            prefs = get_prefs() or {}
            prefs["pending_key"] = "price"
            prefs["last_question"] = first_q
            save_prefs(prefs)
            first_q = format_question_for_ui(first_q, answers)
            return jsonify({"mode":"intro","reply":welcome,"next":first_q})



    prefs = get_prefs()
    answers = prefs["answers"]
    prefs.setdefault("_skip", [])
    
    if is_new_start(user_input, answers):
        prefs = {"answers": {}, "asked": [], "pending_key": "price", "last_question": None, "_skip": []}
        save_prefs(prefs)

        welcome = "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö üòä"
        try:
            q = (choose_natural_question("price", get_prefs().get("answers", {}), get_prefs()) or FIRST_Q).strip()
        except Exception:
            q = FIRST_Q
        prefs = get_prefs() or {}
        prefs["pending_key"] = "price"
        prefs["last_question"] = q
        save_prefs(prefs)
        return jsonify({
            "mode": "intro",
            "reply": welcome,
            "next": q
        })


    if prefs.get("pending_key"):
        key = prefs["pending_key"].lower()
        ui = user_input.lower()
        prefs.setdefault("_skip", [])

        if no_answer(ui):
            if key not in prefs["_skip"]: prefs["_skip"].append(key)
            prefs["pending_key"] = None
            save_prefs(prefs)
        else:
            if key in ("budget", "price"):
                pmin, pmax = extract_price_range(ui)
                if re.search(r"(‡∏á‡∏ö\s*)?(‡πÄ‡∏Å‡∏¥‡∏ô|‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤|>)+\s*\d", ui.replace(" ", "")):
                    answers["price"] = (None, None) 
                else:
                    answers["price"] = (pmin, pmax) if (pmin or pmax) else answers.get("price")
            elif key == "make":
                result = extract_make_from_query(user_input)
                if result:
                    if "make" in result:
                        answers["make"] = result["make"]
                    if "series" in result:         
                        answers["series"] = result["series"]
                else:
                    answers["make"] = answers.get("make")
            elif key in ("trans", "transmission"):
                tr = _extract_transmission(ui)
                answers["trans"] = tr or answers.get("trans")
            elif key == "fuel":
                fu = _extract_fuel(ui)
                answers["fuel"] = fu or answers.get("fuel")
            elif key in ("drive", "drivetrain", "‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô"):
                if "4wd" in ui or "awd" in ui or "‡∏Ç‡∏±‡∏ö‡∏™‡∏µ‡πà" in ui:
                    answers["drive"] = "4WD/AWD"
                elif "‡∏Ç‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤" in ui or "fwd" in ui:
                    answers["drive"] = "FWD"
                elif "‡∏Ç‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏á" in ui or "rwd" in ui:
                    answers["drive"] = "RWD"
            elif key in ("usage", "usage_text"):
                answers["usage_text"] = user_input.strip()
                btxt = answers["usage_text"].lower()
                for _body, _kws in BODY_HINTS.items():
                    if any(w in btxt for w in _kws):
                        answers["body"] = _body
                        break
            elif key == "extra":
                txt = (user_input or "").strip()
                lo  = txt.lower()
                neg = {"‡πÑ‡∏°‡πà‡∏°‡∏µ", "‡πÑ‡∏°‡πà", "no", "none"}
                if txt and lo not in neg:
                    prev = (answers.get("extra_text") or "").strip()
                    answers["extra_text"] = (prev + " " + txt).strip() if prev else txt     

                    m_hp = re.search(r'(\d{2,4})\s*(‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤|hp)\b|\b(‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤)\s*(\d{2,4})', lo)
                    if m_hp:
                        val = m_hp.group(1) or m_hp.group(4)
                        answers["min_hp"] = max(int(answers.get("min_hp") or 0), int(val))
                    m_cc = re.search(r"(\d{3,4})\s*cc", lo)
                    if m_cc:
                        answers["min_cc"] = max(int(answers.get("min_cc") or 0), int(m_cc.group(1)))
            elif key == "model":
                mk = extract_make_from_query(user_input)
                if isinstance(mk, dict):
                    if "make" in mk:
                        answers["make"] = mk["make"]
                    if "series" in mk:        
                        answers["series"] = mk["series"]
                prefs.setdefault("_skip", [])
                if "model" not in prefs["_skip"]:
                    prefs["_skip"].append("model")

        prefs.setdefault("asked", []).append(key)
        prefs["answers"] = answers
        prefs["pending_key"] = None
        handled_pending = True
        save_prefs(prefs)

    pmin_now, pmax_now = extract_price_range(user_input)
    if pmin_now or pmax_now:
        answers["price"] = (pmin_now, pmax_now)

    mk_now = extract_make_from_query(user_input)
    if isinstance(mk_now, dict):
        if "make" in mk_now:
            answers["make"] = mk_now["make"]
        if "series" in mk_now:
            answers["series"] = mk_now["series"]
    elif mk_now:
        answers["make"] = mk_now


    save_prefs(prefs)

    if prefs.get("stage") == "results" and session.get("recent_ids") and not prefs.get("pending_key"):
        ids = session["recent_ids"]
        cols = [
            "full_name","price_thb","engine_l","engine_cc","horsepower_hp",
            "fuel_type","gears","drive","brakes","series","description"
        ]
        try:
            last5 = df.loc[ids, cols].to_dict(orient="records")
        except Exception:
            last5 = df.iloc[ids][cols].to_dict(orient="records")

        reply_text = llm_followup_answer(user_input, last5)
        return jsonify({"mode": "followup", "reply": reply_text, "results": []})
    if prefs.get("stage") != "results":
        if not handled_pending:
            prefs["answers"] = extract_answers(user_input, prefs["answers"])
            answers = prefs["answers"]
            save_prefs(prefs)
        else:
            answers = prefs["answers"]
    else:
        answers = prefs["answers"]

    prefs.setdefault("extra_done", False)  

    core_fields = ["make", "usage_text", "trans", "price", "fuel", "drive"]
    skip = set(prefs.get("_skip", []))
    core_flags = {k: (bool(answers.get(k)) or k in skip) for k in core_fields}
    ready = all(core_flags.values())

    print("DEBUG core_flags:", core_flags, "ready:", ready, "extra_done:", prefs.get("extra_done"))

    if not ready:
        plan = next_question(user_input, answers)
        ask_for = (plan.get("ask_for") or "usage_text").strip().lower()
        follow_q = choose_natural_question(ask_for, answers, prefs).strip()

        if (
            (not follow_q)
            or (follow_q == prefs.get("last_question"))
            or (len(follow_q.split()) > 20)
        ):
            missing = _next_missing_field(answers) or "usage"
            ask_for  = missing
            follow_q = choose_natural_question(ask_for, answers, prefs).strip() or _fallback_question(missing)
        prefs["pending_key"] = ask_for
        prefs["last_question"] = follow_q
        save_prefs(prefs)
        follow_q = format_question_for_ui(follow_q, answers)
        return jsonify({"mode": "ask", "reply": follow_q})


    if ready and not prefs.get("extra_done"):
        q = choose_natural_question("extra", answers, prefs)  
        prefs["pending_key"] = "extra"
        prefs["last_question"] = q
        prefs["extra_done"] = True
        save_prefs(prefs)
        return jsonify({"mode": "ask", "reply": q})
   
    if prefs.get("stage") == "results" and not prefs.get("pending_key"):
        ids = session.get("recent_ids") or []
        last_results = []
        if ids:
            cols = [
            "full_name","price_thb","engine_l","engine_cc","horsepower_hp",
            "fuel_type","gears","drive","brakes","description"
        ]
            try:
                last_results = df.loc[ids, cols].to_dict(orient="records")
            except Exception:
                last_results = df.iloc[ids][cols].to_dict(orient="records")


        ref_idx = detect_reference(user_input, last_results)
        if ref_idx is not None:
            ans = llm_detail_answer(user_input, last_results[ref_idx])
            return jsonify({"mode": "followup", "reply": ans})

        if last_results and is_efficiency_question(user_input):
            def score_eff(r):
                try:
                    eng = float(r.get("engine_l") or 99)
                except Exception:
                    eng = 99
                fuel = (r.get("fuel_type") or "").lower()
                bonus = 0
                if any(k in fuel for k in ["hybrid", "hev", "phev", "bev", "ev"]):
                    bonus -= 1.0
                if "diesel" in fuel:
                    bonus -= 0.2
                return eng + bonus

            best = sorted(last_results, key=score_eff)[0]
            msg = (
                f"‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠ ‚Äú{best.get('full_name')}‚Äù "
                f"(‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {best.get('engine_l','-')}L / ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á {best.get('fuel_type','-')}). "
                f"‡∏≠‡∏¢‡∏≤‡∏Å‡∏ó‡∏£‡∏≤‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏´‡∏°?"
            )
            return jsonify({"mode": "followup", "reply": msg})

        if last_results and is_compare_intent(user_input):
            follow = llm_followup_answer(user_input, last_results)
            return jsonify({"mode": "followup", "reply": follow})

        follow = rag_answer_followup(user_input, last_results)
        return jsonify({"mode": "followup", "reply": follow})


    if any(word in user_input for word in ["‡πÑ‡∏´‡∏°", "‡∏î‡∏µ‡πÑ‡∏´‡∏°", "‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÑ‡∏´‡∏°", "‡∏Ñ‡∏∏‡πâ‡∏°‡πÑ‡∏´‡∏°", "‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤", "‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°"]):
        try:
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡∏≠‡∏¥‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"},
                    {"role": "user", "content": user_input},
                ],
                temperature=0.7,
                max_tokens=600,
            )
            reply = (resp.choices[0].message.content or "").strip()
            return jsonify({"mode": "followup", "reply": reply})
        except Exception as e:
            print("Open-style answer error:", e)
 
    price_min = price_max = None
    if answers.get("price"):
        price_min, price_max = answers["price"]
    target_make = answers.get("make")
    if answers.get("make") and not answers.get("series"):
        ui_lc = user_input.lower().strip()
        mk = str(answers["make"]).lower().strip()
        m = re.search(rf"\b{re.escape(mk)}\s+([a-z0-9‡∏Å-‡πô:.-]+)", ui_lc)
        if m:
            cand = (m.group(1) or "").strip()
            root = cand.split()[0]
            bad = {"‡∏Å‡∏±‡∏ö", "‡πÅ‡∏•‡∏∞", "‡∏´‡∏£‡∏∑‡∏≠", "and", "or"}
            if root not in bad and re.search(r"[a-z0-9‡∏Å-‡πô]", root) and len(root) >= 2:
                answers["series"] = root
    if answers.get("series"):
        sr = str(answers["series"]).lower()
        if not df["series"].fillna("").astype(str).str.lower().str.contains(sr).any():
            answers.pop("series", None)
    _series = str((answers or {}).get("series", "")).strip().lower()
    s_norm  = _series.replace(" ", "")  
    if _series in {"‡πÑ‡∏°‡πà‡∏°‡∏µ", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ", "‡∏£‡∏∏‡πà‡∏ô‡πÑ‡∏´‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ", "‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà", "‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"} \
    or s_norm in {"‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ".replace(" ", ""), "‡∏£‡∏∏‡πà‡∏ô‡πÑ‡∏´‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ".replace(" ", ""), "‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"}: 
        answers.pop("series", None)
    _body_from_now = None
    btxt_now = f"{answers.get('usage_text','')} {user_input}".lower()
    for _b, _kws in BODY_HINTS.items():
        if any(w in btxt_now for w in _kws):
            _body_from_now = _b
            break
    if _body_from_now:
        answers["body"] = _body_from_now

    combined_query = " ".join([
    user_input,
    answers.get("make", ""),
    answers.get("series", ""),
    answers.get("usage_text", "")
    ]).strip()

    

    results = search_similar_rows(
        user_query=combined_query,
        price_min=price_min,
        price_max=price_max,
        target_make=target_make,
        target_series=answers.get("series"),
        top_n=5,
        usage_hints=answers.get("usage", []),
        answers=answers,
    )


    top_rows = [row for _, row in results]
    if price_max is not None:
        top_rows = [
            r for r in top_rows if float(r.get("price_thb", 0)) <= float(price_max)
        ]
  
    if "min_cc" in answers:
        top_rows = [
            r for r in top_rows
            if r.get("engine_cc") and int(r["engine_cc"]) >= answers["min_cc"]
    ]
    if answers.get("series"):
        sr = str(answers["series"]).lower()
        top_rows = [r for r in top_rows if sr in str(r.get("series", "")).lower()]

    print("=== DEBUG FINAL (exactly the same as UI) ===")
    for i, r in enumerate(top_rows[:5], 1):
        try:
            name  = str(r.get("full_name") or "")
           
            price = float(r.get("price_thb") or 0)
            print(f"FINAL >> {i}. {name} |  ‡∏£‡∏≤‡∏Ñ‡∏≤: {price:,.0f} ‡∏ö‡∏≤‡∏ó")
        except Exception:
            pass
    gpt_explanations = rag_generate_answer(top_rows, user_input) if top_rows else []

    rendered, serializable = [], []
    for i, row in enumerate(top_rows):
        eng_l = row.get("engine_l", np.nan)
        cc    = row.get("engine_cc", np.nan)
        hp_raw = row.get("horsepower_hp", np.nan)
        fuel_raw = row.get("fuel_type", "")
        gears_raw = row.get("gears", "")

        engine_text = f"{float(eng_l):.1f} L" if pd.notna(eng_l) else "---"
        if pd.notna(cc):
            try:
                engine_text = (engine_text if engine_text != "---" else "") + f" ({int(cc)} cc)"
                engine_text = engine_text.strip()
            except Exception:
                pass

        hp_val = pd.to_numeric(hp_raw, errors="coerce")
        if pd.isna(hp_val):
            m = re.search(r"(\d+)", str(hp_raw))
            hp_val = int(m.group(1)) if m else np.nan
        hp_text = f"{int(hp_val)} ‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤" if pd.notna(hp_val) else "---"

        fuel_text = fuel_to_thai(fuel_raw) or (str(fuel_raw).strip() or "---")

        if pd.isna(gears_raw) or str(gears_raw).strip() == "":
            gears_text = "---"
        else:
            gears_num = pd.to_numeric(gears_raw, errors="coerce")
            gears_text = f"{int(gears_num)} ‡∏™‡∏õ‡∏µ‡∏î" if pd.notna(gears_num) else str(gears_raw).strip()

        rendered.append(
            {
                "rank": i + 1,
                "name": row["full_name"],
                "price": int(row["price_thb"]),
                "description": row.get("description", ""),
                "engine_text": engine_text,                 

                "hp_text": hp_text,
                "fuel_text": fuel_text,
                "gears_text": gears_text,
                "brakes_text": str(row.get("brakes", "")).strip() or "---",
                "drive_text": (str(row.get("drive", "")).strip().upper() or "---"),
                "year": safe_int(row.get("year")),         
                "series": (str(row.get("series")).strip() if row.get("series") is not None else None),   
                "ai_explanation": (gpt_explanations[i] if i < len(gpt_explanations) else ""),
            }
        )

        serializable.append(
            {
                "full_name": (str(row.get("full_name")) if row.get("full_name") is not None else None),
                "price_thb": safe_int(row.get("price_thb")),
                "engine_l":  safe_float(row.get("engine_l")),
                "engine_cc": safe_int(row.get("engine_cc")),    
                "horsepower_hp": safe_int(row.get("horsepower_hp")),
                "fuel_type": (str(row.get("fuel_type")) if row.get("fuel_type") is not None else None),
                "gears": parse_gears(row.get("gears")),
                "drive": (str(row.get("drive")) if row.get("drive") is not None else None),
                "brakes": (str(row.get("brakes")) if row.get("brakes") is not None else None),
                "year": safe_int(row.get("year")),               
                "series": (str(row.get("series")) if row.get("series") is not None else None),  
                "description": (str(row.get("description")) if row.get("description") is not None else None),
            }
        )

    try:
        session["recent_ids"] = [int(r.get("row_id")) for r in top_rows[:5]]
    except Exception:
        session["recent_ids"] = list(range(len(top_rows[:5])))

    try:
        session["last_results"] = [ int(r.get("row_id")) for r in top_rows[:5] ]
    except Exception:
       
        session["last_results"] = list(range(len(top_rows[:5])))
    prefs["stage"] = "results"
    prefs["pending_key"] = None
    save_prefs(prefs)


    if rendered:
        reply = f"‡πÄ‡∏£‡∏≤‡∏Ç‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ó‡∏±‡πâ‡∏á {len(rendered)} ‡∏Ñ‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
    else:
        reply = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡πÄ‡∏õ‡∏Ñ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"

    print("=== DEBUG FAISS (exactly the same as UI) ===")
    _qemb = model.encode([combined_query]).astype("float32")
    faiss.normalize_L2(_qemb)

    for i, r in enumerate(top_rows[:5], 1):
        try:
            sc = r.get("_final_sc")
            if sc is None:
                rid = int(r.get("row_id"))
                x = np.asarray(index.reconstruct(rid), dtype="float32")
                sc = float(((_qemb[0] - x) ** 2).sum())
            else:
                sc = float(sc)

            l2sq = sc
            cos  = 1.0 - (l2sq / 2.0)
            legacy = 18.0 + 1.75 * l2sq
            name = str(r.get("full_name") or "")
            print(f"DEBUG >> PF {i}. {name} | L2^2*: {l2sq:.4f} | cos*: {cos:.3f} | FAISS*(18‚Äì25): {legacy:.2f}")
        except Exception:
            pass


    return jsonify(
        json_safe({"mode": "recommend", "reply": reply, "results": rendered})
    )
    
    
@app.route("/followup", methods=["POST"])
def followup():
    data = request.get_json(force=True) or {}
    user_input = (data.get("message") or "").strip()
    last_results = session.get("last_results") or []
    if last_results and isinstance(last_results[0], (int, np.integer)):
        cols = [
            "full_name","price_thb","engine_l","engine_cc","horsepower_hp",
            "fuel_type","gears","drive","brakes","series","description"
        ]
        try:
            last_results = df.loc[last_results, cols].to_dict(orient="records")
        except Exception:
            last_results = df.iloc[last_results][cols].to_dict(orient="records")

    if not last_results:
        return jsonify(
            {"mode": "ask", "reply": "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡∏û‡∏¥‡∏°‡∏û‡πå ‚Äú‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö"}
        )

    m = re.search(r"‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*(\d+)", user_input)
    if m:
        idx = int(m.group(1)) - 1
        if 0 <= idx < len(last_results):
            car = last_results[idx]
            eng_line = f"{car.get('engine_l','-')}L"
            if car.get('engine_cc') not in (None, "", "nan"):
                try:
                    eng_line = (eng_line if eng_line != "-" else "") + f" ({int(car.get('engine_cc'))} cc)"
                except Exception:
                    pass
            text = (
                f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‚Äú{car.get('full_name')}‚Äù ‡∏õ‡∏µ {car.get('year','-')} / ‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå {car.get('series','-')} | "
                f"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {eng_line} | "
                f"‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤ {car.get('horsepower_hp','-')} | "
                f"‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á {car.get('fuel_type','-')} | ‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå {car.get('gears','-')}"
            )
            return jsonify({"mode": "followup", "reply": text})


    if is_efficiency_question(user_input):

        def score(r):
            try:
                eng = float(r.get("engine_l") or 9)
            except:
                eng = 9
            fuel = (r.get("fuel_type") or "").lower()
            bonus = -1 if any(k in fuel for k in ["hev", "hybrid", "ev", "phev"]) else 0
            return eng + bonus

        best = sorted(last_results, key=score)[0]
        return jsonify(
            {
                "mode": "followup",
                "reply": f"‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏π‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠ ‚Äú{best.get('full_name')}‚Äù ‡∏Ñ‡∏£‡∏±‡∏ö",
            }
        )

    return jsonify(
        {
            "mode": "followup",
            "reply": "‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà 1‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏Ñ‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏™‡∏∏‡∏î‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å 5 ‡∏Ñ‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö",
        }
    )

if __name__ == "__main__":
    app.run(debug=True)
